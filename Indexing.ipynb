{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcuEHtGFoOqt"
   },
   "source": [
    "# Indexing excercise \n",
    "\n",
    "In this excercise, we are going to index the [MS MARCO](http://www.msmarco.org/) passage collection and explore some features of the index.\n",
    "\n",
    "We use [Anserini](https://github.com/castorini/anserini]) toolkit and its python interface [Pyserini](https://github.com/castorini/pyserini)  to run our experiments. \n",
    "\n",
    "***This notebook is created based on Anserini/Pyserini tutorials. You can learn more by checking their repositories and tutorials.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egQ3UlHWpj0K"
   },
   "source": [
    "## 1. Setup the environmet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzPu9N_Md8iB"
   },
   "source": [
    "Install Pyserini via PyPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kqQkZ_1cqjVJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyserini"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'D:\\Programs\\Anaconda\\envs\\ir\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\nilsk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8u0zmblp\\\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\nilsk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8u0zmblp\\\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\nilsk\\AppData\\Local\\Temp\\pip-wheel-bvwwfx8j'\n",
      "       cwd: C:\\Users\\nilsk\\AppData\\Local\\Temp\\pip-install-8u0zmblp\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\n",
      "  Complete output (7 lines):\n",
      "  Dependence list: ['pybind11<2.6.2', 'psutil', \"numpy>=1.10.0,<1.17 ; python_version=='2.7'\", \"numpy>=1.10.0 ; python_version>='3.5'\"]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\\\\"2.1.1\\\\\"']\n",
      "  building 'nmslib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for nmslib\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'D:\\Programs\\Anaconda\\envs\\ir\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\nilsk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8u0zmblp\\\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\nilsk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8u0zmblp\\\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\nilsk\\AppData\\Local\\Temp\\pip-record-uek03jry\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Programs\\Anaconda\\envs\\ir\\Include\\nmslib'\n",
      "         cwd: C:\\Users\\nilsk\\AppData\\Local\\Temp\\pip-install-8u0zmblp\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\n",
      "    Complete output (7 lines):\n",
      "    Dependence list: ['pybind11<2.6.2', 'psutil', \"numpy>=1.10.0,<1.17 ; python_version=='2.7'\", \"numpy>=1.10.0 ; python_version>='3.5'\"]\n",
      "    running install\n",
      "    running build\n",
      "    running build_ext\n",
      "    Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\\\\"2.1.1\\\\\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pyserini-0.13.0-py3-none-any.whl (72.8 MB)\n",
      "Collecting Cython>=0.29.21\n",
      "  Downloading Cython-0.29.24-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "Collecting pyjnius>=1.2.1\n",
      "  Downloading pyjnius-1.4.0-cp39-cp39-win_amd64.whl (217 kB)\n",
      "Collecting pandas>=1.1.5\n",
      "  Downloading pandas-1.3.3-cp39-cp39-win_amd64.whl (10.2 MB)\n",
      "Collecting scikit-learn>=0.22.1\n",
      "  Downloading scikit_learn-0.24.2-cp39-cp39-win_amd64.whl (6.9 MB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
      "Collecting nmslib\n",
      "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
      "Collecting scipy>=1.4.1\n",
      "  Downloading scipy-1.7.1-cp39-cp39-win_amd64.whl (33.8 MB)\n",
      "Collecting transformers>=4.6.0\n",
      "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
      "Collecting sentencepiece>=0.1.95\n",
      "  Downloading sentencepiece-0.1.96-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Collecting numpy>=1.18.1\n",
      "  Using cached numpy-1.21.2-cp39-cp39-win_amd64.whl (14.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\programs\\anaconda\\envs\\ir\\lib\\site-packages (from pandas>=1.1.5->pyserini) (2.8.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Requirement already satisfied: six>=1.7.0 in d:\\programs\\anaconda\\envs\\ir\\lib\\site-packages (from pyjnius>=1.2.1->pyserini) (1.16.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting huggingface-hub>=0.0.12\n",
      "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-win_amd64.whl (213 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2021.8.28-cp39-cp39-win_amd64.whl (271 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: packaging in d:\\programs\\anaconda\\envs\\ir\\lib\\site-packages (from transformers>=4.6.0->pyserini) (21.0)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\programs\\anaconda\\envs\\ir\\lib\\site-packages (from packaging->transformers>=4.6.0->pyserini) (2.4.7)\n",
      "Requirement already satisfied: colorama in d:\\programs\\anaconda\\envs\\ir\\lib\\site-packages (from tqdm->pyserini) (0.4.4)\n",
      "Collecting pybind11<2.6.2\n",
      "  Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "Collecting psutil\n",
      "  Using cached psutil-5.8.0-cp39-cp39-win_amd64.whl (246 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\anaconda\\envs\\ir\\lib\\site-packages (from requests->transformers>=4.6.0->pyserini) (2021.5.30)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Building wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (setup.py): started\n",
      "  Building wheel for nmslib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for nmslib\n",
      "Failed to build nmslib"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    building 'nmslib' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'D:\\Programs\\Anaconda\\envs\\ir\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\nilsk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8u0zmblp\\\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\nilsk\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8u0zmblp\\\\nmslib_20f4cabfa36e4704bb238065d4bc1f38\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\nilsk\\AppData\\Local\\Temp\\pip-record-uek03jry\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Programs\\Anaconda\\envs\\ir\\Include\\nmslib' Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, typing-extensions, tqdm, requests, regex, numpy, joblib, filelock, click, tokenizers, threadpoolctl, scipy, sacremoses, pyyaml, pytz, pybind11, psutil, huggingface-hub, transformers, sentencepiece, scikit-learn, pyjnius, pandas, nmslib, Cython, pyserini\n",
      "    Running setup.py install for nmslib: started\n",
      "    Running setup.py install for nmslib: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install pyserini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuqRujlSfnTS"
   },
   "source": [
    "Clone the Ansirini repository from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Gk8iQNMZASg"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/castorini/anserini.git\n",
    "!cd anserini && git checkout ad5ba1c76196436f8a0e28efdb69960d4873efe3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcU5a-ETrqnT"
   },
   "source": [
    "## 2. Get the collection and prepare the files\n",
    "MS MARCO (MicroSoft MAchine Reading COmprehension) is a large-scale dataset that defines many tasks from question answering to ranking. Here we focus on the collection designed for passage re-ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AJ8rwE1SIEZ"
   },
   "outputs": [],
   "source": [
    "!wget https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz -P data/msmarco_passage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLxsYuTESft4"
   },
   "outputs": [],
   "source": [
    "!ls data/msmarco_passage/ \n",
    "!tar xvfz data/msmarco_passage/collection.tar.gz -C data/msmarco_passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtK9rHMOwjYx"
   },
   "source": [
    "The original MS MARCO collection is a tab-separated values (TSV) file. We need to convert the collection into the jsonl format that can be processed by Anserini. jsonl files contain JSON object per line.\n",
    "\n",
    "This command generates 9 jsonl files in your data/msmarco_passage/collection_jsonl directory, each with 1M lines (except for the last one, which should have 841,823 lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QX-GNGyLZzN2"
   },
   "outputs": [],
   "source": [
    "!cd anserini && python ./src/main/python/msmarco/convert_collection_to_jsonl.py \\\n",
    " --collection_path ../data/msmarco_passage/collection.tsv --output_folder ../data/msmarco_passage/collection_jsonl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDXFZHf_5lR-"
   },
   "source": [
    "**Check the data!**\n",
    "\n",
    "jsonl files are JSON files with keys id and contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rv0gF3srw39p"
   },
   "outputs": [],
   "source": [
    "!wc -l data/msmarco_passage/collection_jsonl/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3hFwpsg5DC8"
   },
   "outputs": [],
   "source": [
    "!head -5 data/msmarco_passage/collection_jsonl/docs00.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAu65qTQ6KNz"
   },
   "source": [
    "Remove the original files to make room for the index. \n",
    "Check the contents of `data/msmarco_passage` before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85ZW8BUt6JOK"
   },
   "outputs": [],
   "source": [
    "!ls data/msmarco_passage\n",
    "!rm data/msmarco_passage/*.tsv\n",
    "!ls data/msmarco_passage\n",
    "!rm -rf sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf4Kxgpq6vna"
   },
   "source": [
    "## 3. Generate the index\n",
    "Some common indexing options with Anserini:\n",
    "\n",
    "* input: Path to collection\n",
    "* threads: Number of threads to run\n",
    "* collection: Type of Anserini Collection, e.g., LuceneDocumentGenerator, TweetGenerator (subclass of LuceneDocumentGenerator for TREC Microblog)\n",
    "* index: Path to index output\n",
    "* storePositions: Boolean flag to store positions\n",
    "* storeDocvectors: Boolean flag to store document vbectors\n",
    "* storeRawDocs: Boolean flag to store raw document text\n",
    "* keepStopwords: Boolean flag to keep stopwords (False by default)\n",
    "* stemmer: Stemmer to use (Porter by default)\n",
    "\n",
    "We now have everything in place to index the collection. The indexing speed may vary,the process takes about 10 minutes in Google colab.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9xTzmbP7J1u"
   },
   "outputs": [],
   "source": [
    "!python -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator -threads 9 \\\n",
    "-input data/msmarco_passage/collection_jsonl -index indexes/lucene-index-msmarco-passage -storePositions -storeDocvectors -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWl9RgbZ7dSv"
   },
   "source": [
    "Check the size of the index at the specified destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_Nigxvr8DIK"
   },
   "outputs": [],
   "source": [
    "!ls indexes\n",
    "!du -h indexes/lucene-index-msmarco-passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZMAtCEE-f0q"
   },
   "source": [
    "##4. Explore the index\n",
    "\n",
    "We can now explore the index using the The IndexReader class of Pyserini. \n",
    "\n",
    "Read [Usage of the Index Reader API](https://github.com/castorini/pyserini/blob/master/docs/usage-indexreader.md) notebook for more information on accessing and manipulating an inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Pf0oDQfgp7l-"
   },
   "outputs": [],
   "source": [
    "from pyserini.index import IndexReader\n",
    "\n",
    "index_reader = IndexReader('indexes/lucene-index-msmarco-passage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bI2092DyZ94"
   },
   "source": [
    "Compute the collection and document frequencies of a term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCLM4LYQqRQ9"
   },
   "outputs": [],
   "source": [
    "term = 'played'\n",
    "\n",
    "# Look up its document frequency (df) and collection frequency (cf).\n",
    "# Note, we use the unanalyzed form:\n",
    "df, cf = index_reader.get_term_counts(term)\n",
    "\n",
    "analyzed_form = index_reader.analyze(term)\n",
    "print(f'Analyzed form of term \"{analyzed_form[0]}\": df={df}, cf={cf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMwpOyMTulz2"
   },
   "source": [
    "Get basic index statistics of the index.\n",
    "\n",
    "Note that unless the underlying index was built with the `-optimize` option (i.e., merging all index segments into a single segment), unique_terms will show -1 (nope, that's not a bug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_PeXpvwuXmM"
   },
   "outputs": [],
   "source": [
    "index_reader.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zwI-Qlmu_RS"
   },
   "source": [
    "Get the postings list of a term, and traverse postings.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saZQa6Qgu-L2"
   },
   "outputs": [],
   "source": [
    "term = \"played\"\n",
    "\n",
    "postings_list = index_reader.get_postings_list(term)\n",
    "for posting in postings_list:\n",
    "    print(f'docid={posting.docid}, tf={posting.tf}, pos={posting.positions}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Indexing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
